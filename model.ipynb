{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17929,"status":"ok","timestamp":1683691571197,"user":{"displayName":"박희민","userId":"08232915071664532971"},"user_tz":-540},"id":"Q6HpCe-AJc_r","outputId":"2a07ff4c-e323-4f88-bd95-9fe226ea46c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1683691571198,"user":{"displayName":"박희민","userId":"08232915071664532971"},"user_tz":-540},"id":"7igTM1oAJqiR","outputId":"3b55b8ea-9c55-40b2-8d61-0864f39c5d28"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["%cd /content/drive/MyDrive/Colab Notebooks"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"executionInfo":{"elapsed":137377,"status":"error","timestamp":1683691708573,"user":{"displayName":"박희민","userId":"08232915071664532971"},"user_tz":-540},"id":"emf98gilJz0k","outputId":"30bbe97f-7e73-405c-c023-e1eeb9e50dbc","scrolled":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu device\n","Epoch 1\n","-------------------------------\n","mean loss: 0.059645\n","Validation MAE: 0.217426 \n","\n","Epoch 2\n","-------------------------------\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-243bdd486d95>\u001b[0m in \u001b[0;36m<cell line: 99>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Epoch {t + 1}\\n-------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-243bdd486d95>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Compute prediction error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# y.reshape((-1,1)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-3-243bdd486d95>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mc_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mhn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    813\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    814\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import statistics\n","\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from ApDataset import PmAwsDataset\n","import numpy as np\n","import copy\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","\n","batch_size = 512\n","num_input = 48\n","\n","# Get cpu or gpu device for training.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")\n","\n","\n","# Define model\n","class LSTM(nn.Module):\n","    def __init__(self):\n","        super(LSTM, self).__init__()\n","        self.num_layers = num_layers\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_classes = num_classes\n","\n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)\n","        self.fc_1 = nn.Linear(hidden_size, 256)\n","        self.fc_2 = nn.Linear(256, 128)\n","        self.fc = nn.Linear(128, num_classes)\n","        self.dropout = nn.Dropout(0.2)\n","\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        output, (hn, cn) = self.lstm(x, (h_0, c_0))\n","\n","        hn = hn.view(-1, self.hidden_size)\n","        out = self.relu(hn)\n","        out = self.dropout(out)\n","        out = self.fc_1(out)\n","        out = self.fc_2(out)\n","        out = self.relu(out)\n","        out = self.fc(out)\n","        return out[:, 0]\n","\n","\n","def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset)\n","    model.train()\n","    mean_loss = 0\n","    count_loss = 0\n","    for batch, (X, y) in enumerate(dataloader):\n","        X, y = X.to(device), y.to(device)\n","\n","        # Compute prediction error\n","        pred = model(X)\n","        loss = loss_fn(pred, y)  # y.reshape((-1,1)))\n","\n","        # Backpropagation\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        mean_loss += loss.item()\n","        count_loss += len(X)\n","\n","    mean_loss /= count_loss\n","    print(f\"mean loss: {mean_loss:>7f}\")\n","\n","\n","def test(dataloader, model, loss_fn, mode='val'):\n","    size = len(dataloader.dataset)\n","    num_batches = len(dataloader)\n","    model.eval()\n","    test_loss = 0\n","    count_test = 0\n","    with torch.no_grad():\n","        for X, y in dataloader:\n","            X, y = X.to(device), y.to(device)\n","            pred = model(X)\n","            test_loss += loss_fn(pred, y).item()  # y.reshape(-1,1)).item()\n","            count_test += len(X)\n","    test_loss /= count_test\n","    test_loss = np.sqrt(test_loss)\n","    if mode == 'val':\n","        print(f\"Validation MAE: {test_loss:>7f} \\n\")\n","    else:\n","        print(f\"Test MAE: {test_loss:>7f} \\n\")\n","\n","    return test_loss\n","\n","\n","for nf in range(1, 18):\n","\n","    ap_train = PmAwsDataset(\"train\", num_input=num_input, num_file=nf)\n","    ap_val = PmAwsDataset(\"val\", num_input=num_input, num_file=nf)\n","    ap_test = PmAwsDataset(\"test\", num_input=num_input, num_file=nf)\n","\n","    train_dataloader = DataLoader(ap_train, batch_size=batch_size)\n","    val_dataloader = DataLoader(ap_val, batch_size=batch_size)\n","    test_dataloader = DataLoader(ap_test, batch_size=batch_size)\n","\n","    epochs = 1000\n","    max_tolerance = 100\n","    input_size = 6\n","    num_layers = 1\n","    hidden_size = 512\n","    num_classes = 1\n","    y_pred_lstm = []\n","    path = f'./model.pt'\n","    tolerance = 0\n","    best_val_loss = np.finfo(float).max\n","    if nf == 1:\n","        model = LSTM().to(device)\n","    else:\n","        model = torch.load(path)\n","\n","    loss_fn = nn.L1Loss(reduction=\"sum\")\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","\n","    for t in range(epochs):\n","        print(f\"Epoch {t + 1}\\n-------------------------------\")\n","        train(train_dataloader, model, loss_fn, optimizer)\n","        val_loss = test(val_dataloader, model, loss_fn)\n","        if val_loss > best_val_loss:\n","            if tolerance > max_tolerance:\n","                break\n","            else:\n","                tolerance += 1\n","        else:\n","            best_val_loss = val_loss\n","    path = f'./model.pt'\n","    torch.save(model, path)\n","    print(\"Done!\")\n","\n","    path = f'./model.pt'\n","    net = torch.load(path)\n","\n","    loss_fn = nn.L1Loss(reduction=\"sum\")\n","    test_loss = test(test_dataloader, net, loss_fn, mode='test')\n","\n","    X, y_gt_ = ap_test[0:]\n","    X = torch.Tensor(X).to(device)\n","    y = net(X)\n","    y_gt = y_gt_[0]\n","    y_pred_lstm.append((y).detach().cpu().numpy()[:])\n","    y_pred_lstm = np.array(y_pred_lstm)\n","    y_pred_lstm = np.ravel(y_pred_lstm, order='C')\n","    print(y_pred_lstm)\n","    print(y_gt_)\n","    plt.scatter(y_gt_, y_pred_lstm)\n","    plt.xlabel(\"True Values\")\n","    plt.ylabel(\"Predictions\")\n","    plt.show()\n","\n","    # Correlation coefficient\n","    correlation_matrix = np.corrcoef(y_gt_, y_pred_lstm)\n","    correlation_coefficient = correlation_matrix[0, 1]\n","    print(\"Correlation coefficient:\", correlation_coefficient)\n","    # px = np.arange(1, 7013)\n","    # py1 = y_pred_lstm\n","    # py2 = y_gt_\n","    # # 하나의 그래프 영역에 두 개의 그래프 그리기\n","    # fig, ax = plt.subplots(figsize=(25, 7))\n","    # ax.plot(px, py1, label='y1')\n","    # ax.plot(px, py2, label='y2')\n","\n","    # # 그래프 제목, 레이블 등 설정하기\n","    # ax.set_title('Comparison of y1 and y2')\n","    # ax.set_xlabel('X axis')\n","    # ax.set_ylabel('Y axis')\n","    # ax.legend()\n","\n","    # # 그래프 보여주기\n","    # plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":248},"id":"jFKDrSBLuDcq","executionInfo":{"status":"error","timestamp":1683644369520,"user_tz":-540,"elapsed":4,"user":{"displayName":"박희민","userId":"08232915071664532971"}},"outputId":"ffc07476-3c0d-4a63-e6d8-e58cd7bed8e8"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-7d2664b59aac>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'./model.pt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0map_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPmAwsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pred\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"]}],"source":["path = f'./model.pt'\n","model = torch.load(path)\n","model.eval()\n","\n","ap_pred = PmAwsDataset(\"pred\", num_input=num_input)\n","pred_dataloader = DataLoader(ap_pred, batch_size=batch_size)\n","\n","pred_list = []\n","\n","for i in range(len(ap_pred)):\n","    X, y = ap_pred[i]\n","    if np.isnan(y):\n","        with torch.no_grad():\n","            tensor_input_data = torch.Tensor(X).to(device)\n","            tensor_input_data = tensor_input_data.unsqueeze(dim=0)\n","            pred_data = model(tensor_input_data)\n","            pred_data = pred_data.detach().cpu().numpy()\n","            pred_list.append(pred_data)\n","            for j in range(48):\n","                ap_pred[i + j + 1][0][47 - j][0] = pred_data\n","\n","    else:\n","        continue\n","ans = pd.read_csv('answer_sample.csv')\n","pred_list = pd.DataFrame(pred_list)\n","pred_list.to_csv('pm_data.csv')\n","ans = ans\n","result = pd.concat([ans, pred_list], axis=1)\n","\n","result.to_csv('result.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dfFhqfMQuDcq"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}